services:
  ollama-webui-cpu:
    image: ghcr.io/open-webui/open-webui:git-09a81eb
    container_name: ollama_webui_cpu
    expose:
      - 8080/tcp
    ports:
      - "8086:8080"
    environment:
      - OLLAMA_BASE_URL=http://ollama-gpu:11435
    volumes:
      - ./open-webui:/app/backend/data
    restart: unless-stopped
    depends_on:
      - ollama-cpu
    # networks:
    #   - shared-network

  ollama-cpu:
    image: ollama/ollama
    container_name: ollama_cpu
    devices:
      - /dev/dri:/dev/dri
    environment:
      - OLLAMA_DEBUG=1
    ########
    volumes:
      - ./ollama:/root/.ollama
    # expose:
    #   - 11434
    ports:
      - 11435:11434
    restart: unless-stopped
    # networks:
    #   - shared-network


    # networks:
    #   shared-network:
    #     external: true
